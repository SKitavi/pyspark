{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RJLqL2rNHmDOCbMUTOtR0flgMudQ3_3a",
      "authorship_tag": "ABX9TyNv/rYQ4sKCC5/11yHxFz+m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKitavi/pyspark/blob/main/Spark_ML_Lib_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Setting Up the Environment**"
      ],
      "metadata": {
        "id": "hgps6C-Gf1qC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Q-oc6WTnPz",
        "outputId": "723d7057-1a49-48b5-a270-016bd115e3ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "C7NhfQvgUFW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Loading the Dataset**\n",
        "\n",
        "* The dataset used is California Housing Prices (from\n",
        "Kaggle).\n",
        "* It is loaded into PySpark DataFrame for distributed processing:"
      ],
      "metadata": {
        "id": "bh8vUg-Mffyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CaliforniaHousing\").getOrCreate()\n",
        "df = spark.read.csv(\"housing.csv\", header=True,\n",
        "inferSchema=True)"
      ],
      "metadata": {
        "id": "S__8YWoBaWkO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "nHRNsJfUb7rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c5124d-f933-4cc1-9a63-3a04ba251845"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            " |-- ocean_proximity: string (nullable = true)\n",
            "\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
            "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
            "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Data Preprocessing**\n",
        "\n",
        "* Handling missing values:\n",
        "\n"
      ],
      "metadata": {
        "id": "OCfxE19RgYFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "QY6DxlNNgEH7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Selecting features and the target variable:"
      ],
      "metadata": {
        "id": "9y2_WBLigkHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_cols = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        " 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_transformed = assembler.transform(df)"
      ],
      "metadata": {
        "id": "7FK-fLitgoXL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Splitting Data for Training and Testing**\n",
        "* The dataset is split into training and test sets:\n",
        "\n"
      ],
      "metadata": {
        "id": "pGupR_Syhid5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_transformed.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "5K42eMBxhKLB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Building a Machine Learning Model**\n",
        "* Using Linear Regression from PySpark MLlib:"
      ],
      "metadata": {
        "id": "2ffSDDnshwjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "la5fUMXBiE1j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
        "model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "Cshmxe5OisuP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Evaluating the Model**\n",
        "* Predictions on test data:"
      ],
      "metadata": {
        "id": "b26N7OVji61Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"median_house_value\", \"prediction\").show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nxvm2qhjB2w",
        "outputId": "3d599dbf-f9bf-4ddd-cf12-eb85a7fcd854"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|median_house_value|        prediction|\n",
            "+------------------+------------------+\n",
            "|          103600.0|102138.32319061086|\n",
            "|          106700.0|190038.23036733456|\n",
            "|           73200.0| 77197.94015233312|\n",
            "|           90100.0| 165461.8792793178|\n",
            "|           67000.0|120982.11327198846|\n",
            "|           86400.0|  155596.987874303|\n",
            "|           70500.0|128682.11129985936|\n",
            "|           85100.0| 148049.0329841054|\n",
            "|           80500.0| 148573.9335442488|\n",
            "|           96000.0|  133456.888130059|\n",
            "|           75500.0| 97768.32878634613|\n",
            "|           75000.0| 50460.39456075849|\n",
            "|          100600.0|156059.88453309098|\n",
            "|           74100.0|122045.03343804413|\n",
            "|           66800.0| 99964.70208527287|\n",
            "+------------------+------------------+\n",
            "only showing top 15 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Checking model performance using evaluation metrics:"
      ],
      "metadata": {
        "id": "0uDpcKm3jY3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"median_house_value\",\n",
        "predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqhMe6aCjV4N",
        "outputId": "960a12a2-b6fd-40a2-f491-510078309a9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 69685.92905618671\n"
          ]
        }
      ]
    }
  ]
}