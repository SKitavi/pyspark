{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RJLqL2rNHmDOCbMUTOtR0flgMudQ3_3a",
      "authorship_tag": "ABX9TyM5VDv7BC91oH2NAVnCnBeA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKitavi/pyspark/blob/main/Spark_ML_Intro_(2_California).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Setting Up the Environment**"
      ],
      "metadata": {
        "id": "hgps6C-Gf1qC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Q-oc6WTnPz",
        "outputId": "723d7057-1a49-48b5-a270-016bd115e3ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "C7NhfQvgUFW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Loading the Dataset**\n",
        "\n",
        "* The dataset used is California Housing Prices (from\n",
        "Kaggle).\n",
        "* It is loaded into PySpark DataFrame for distributed processing:"
      ],
      "metadata": {
        "id": "bh8vUg-Mffyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CaliforniaHousing\").getOrCreate()\n",
        "df = spark.read.csv(\"sample_data/california_housing_train.csv\", header=True,\n",
        "inferSchema=True)"
      ],
      "metadata": {
        "id": "S__8YWoBaWkO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "nHRNsJfUb7rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e280b98-4f34-49dd-e11d-2170990df86a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Data Preprocessing**\n",
        "\n",
        "* Handling missing values:\n",
        "\n"
      ],
      "metadata": {
        "id": "OCfxE19RgYFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "QY6DxlNNgEH7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Selecting features and the target variable:"
      ],
      "metadata": {
        "id": "9y2_WBLigkHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_cols = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        " 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_transformed = assembler.transform(df)"
      ],
      "metadata": {
        "id": "7FK-fLitgoXL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Splitting Data for Training and Testing**\n",
        "* The dataset is split into training and test sets:\n",
        "\n"
      ],
      "metadata": {
        "id": "pGupR_Syhid5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_transformed.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "5K42eMBxhKLB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Building a Machine Learning Model**\n",
        "* Using Linear Regression from PySpark MLlib:"
      ],
      "metadata": {
        "id": "2ffSDDnshwjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "la5fUMXBiE1j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
        "model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "Cshmxe5OisuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Evaluating the Model**\n",
        "* Predictions on test data:"
      ],
      "metadata": {
        "id": "b26N7OVji61Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"median_house_value\", \"prediction\").show(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nxvm2qhjB2w",
        "outputId": "7d66113d-e71e-4984-f6f8-f2f3ff0aefc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|median_house_value|        prediction|\n",
            "+------------------+------------------+\n",
            "|          103600.0| 101334.1523250211|\n",
            "|          106700.0|189023.14109935658|\n",
            "|           73200.0| 76469.86363691278|\n",
            "|           90100.0|165186.09220862994|\n",
            "|           67000.0|120101.40360319754|\n",
            "|          116100.0|199313.20768269338|\n",
            "|           62500.0|132221.13859327696|\n",
            "|           85400.0| 157664.6846611374|\n",
            "|           90000.0|174691.75308407517|\n",
            "|           86400.0| 157459.4768907926|\n",
            "|           74100.0|121336.39571196772|\n",
            "|           57500.0|104446.81338756438|\n",
            "|           75100.0| 134649.3450419805|\n",
            "|          130600.0|187192.50846866565|\n",
            "|           92100.0|156258.08505277848|\n",
            "|           90200.0|112560.03201755695|\n",
            "|           92600.0|129170.19603408081|\n",
            "|          165600.0|195263.98156292224|\n",
            "|           36700.0| 38152.75754792476|\n",
            "|          116700.0| 87423.02334289998|\n",
            "|           82400.0|141105.39691865863|\n",
            "|           76800.0| 99441.99060788658|\n",
            "|          101500.0| 138526.8207492167|\n",
            "|           77100.0|106042.36291878251|\n",
            "|          124600.0|162521.58637589822|\n",
            "|           77200.0|122807.48922323342|\n",
            "|           92600.0|137481.73918678472|\n",
            "|          131300.0|199064.46953172516|\n",
            "|          147100.0|187219.20268763276|\n",
            "|          142100.0| 151963.2972592977|\n",
            "|           82300.0| 118130.8956549028|\n",
            "|           61500.0|57867.395323215984|\n",
            "|          112500.0|182775.81725271698|\n",
            "|          118300.0|150053.90903181257|\n",
            "|          153100.0|196284.84970898833|\n",
            "|          262500.0| 227829.5058588474|\n",
            "|          100300.0|114004.27469303086|\n",
            "|          143200.0| 126833.1888968302|\n",
            "|           61700.0|15927.268020115793|\n",
            "|          296800.0| 247055.4381145183|\n",
            "|           73500.0| 37733.13265730208|\n",
            "|          276200.0|271050.15328996256|\n",
            "|          216900.0|231016.33799295034|\n",
            "|          260300.0|  167442.677309304|\n",
            "|          178500.0| 213288.3643133496|\n",
            "|           77800.0|105192.31328057405|\n",
            "|           94700.0|120459.28344286932|\n",
            "|          238800.0| 217981.0162055716|\n",
            "|          248600.0|255500.32678431086|\n",
            "|           66800.0|107614.23738937965|\n",
            "+------------------+------------------+\n",
            "only showing top 50 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Checking model performance using evaluation metrics:"
      ],
      "metadata": {
        "id": "0uDpcKm3jY3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"median_house_value\",\n",
        "predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqhMe6aCjV4N",
        "outputId": "3ffdbea7-795f-4361-d37d-49810ebdb2ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 69231.88317848284\n"
          ]
        }
      ]
    }
  ]
}